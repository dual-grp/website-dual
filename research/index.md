---
title: Research
nav:
  order: 1
  tooltip: Published works
---

# {% include icon.html icon="fa-solid fa-microscope" %}Research

Our research investigates the synergistic interplay of distributed computing, mathematical optimization, and artificial intelligence to create scalable, efficient, and trustworthy machine learning systems. We develop algorithms that jointly exploit distributed architectures and optimization principles to advance the efficiency, fairness, and interpretability of modern AI, with particular emphasis on large language models, federated and edge learning, and real-time collaborative inference. 

At the same time, the team explores both theoretical foundations and practical applications, contributing to the advancement of intelligent systems capable of operating effectively in real-world, resource-constrained environments. This integrated approach delivers new theoretical insights and deployable frameworks for next-generation AI across heterogeneous and dynamic computational settings.

{% include section.html %}

## Highlighted

{% include citation.html lookup="Distributionally Robust Wireless Semantic Communication with Large AI Models" style="rich" show_image=false %}

{% include section.html %}

## All

{% include search-box.html %}

{% include search-info.html %}

{% include list.html data="citations" component="citation" style="rich" show_image=false %}
